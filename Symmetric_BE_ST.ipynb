{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQ3K4h/fkSf6g3A/3pc0XN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sweta-Das/LangChain-HuggingFace-LLM/blob/SentenceTransformers/Symmetric_BE_ST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "%pip -q install langchain sentence-transformers transformers"
      ],
      "metadata": {
        "id": "oZsjSW6aO3_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub\n",
        "import numpy as np\n",
        "import sys, random\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "U0ehNVowOw0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing through HuggingFace Access Token\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'HUGGINGFACEHUB_API_TOKEN'"
      ],
      "metadata": {
        "id": "wXhGndarOtLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Symmetric Semantic Search Binary Encoder"
      ],
      "metadata": {
        "id": "HBaoBkOwOE71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Get our models - The package will take care of downloading the models automatically\n",
        "# For best performance: Muennighoff/SGPT-5.8B-weightedmean-nli-bitfit\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Muennighoff/SGPT-125M-weightedmean-nli-bitfit\")\n",
        "model = AutoModel.from_pretrained(\"Muennighoff/SGPT-125M-weightedmean-nli-bitfit\")\n",
        "# Deactivate Dropout (There is no dropout in the above models so it makes no difference here but other SGPT models may have dropout)\n",
        "model.eval()\n",
        "\n",
        "# Tokenize input texts\n",
        "texts = [\n",
        "    \"deep learning\",\n",
        "    \"artificial intelligence\",\n",
        "    \"deep diving\",\n",
        "    \"artificial snow\",\n",
        "]\n",
        "batch_tokens = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Get the embeddings\n",
        "with torch.no_grad():\n",
        "    # Get hidden state of shape [bs, seq_len, hid_dim]\n",
        "    last_hidden_state = model(**batch_tokens, output_hidden_states=True, return_dict=True).last_hidden_state\n",
        "\n",
        "# Get weights of shape [bs, seq_len, hid_dim]\n",
        "weights = (\n",
        "    torch.arange(start=1, end=last_hidden_state.shape[1] + 1)\n",
        "    .unsqueeze(0)\n",
        "    .unsqueeze(-1)\n",
        "    .expand(last_hidden_state.size())\n",
        "    .float().to(last_hidden_state.device)\n",
        ")\n",
        "\n",
        "# Get attn mask of shape [bs, seq_len, hid_dim]\n",
        "input_mask_expanded = (\n",
        "    batch_tokens[\"attention_mask\"]\n",
        "    .unsqueeze(-1)\n",
        "    .expand(last_hidden_state.size())\n",
        "    .float()\n",
        ")\n",
        "\n",
        "# Perform weighted mean pooling across seq_len: bs, seq_len, hidden_dim -> bs, hidden_dim\n",
        "sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded * weights, dim=1)\n",
        "sum_mask = torch.sum(input_mask_expanded * weights, dim=1)\n",
        "\n",
        "embeddings = sum_embeddings / sum_mask\n",
        "\n",
        "# Calculate cosine similarities\n",
        "# Cosine similarities are in [-1, 1]. Higher means more similar\n",
        "cosine_sim_0_1 = 1 - cosine(embeddings[0], embeddings[1])\n",
        "cosine_sim_0_2 = 1 - cosine(embeddings[0], embeddings[2])\n",
        "cosine_sim_0_3 = 1 - cosine(embeddings[0], embeddings[3])\n",
        "\n",
        "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[1], cosine_sim_0_1))\n",
        "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[2], cosine_sim_0_2))\n",
        "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[3], cosine_sim_0_3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293,
          "referenced_widgets": [
            "6590ab3cce064639b2be40305df3bb58",
            "10287b2b5c4c4c589ff1ffafa7c77914",
            "ad70bf7bb61b439b92fef098e8e66c1a",
            "fcd8890d4ba148f1869e81bc2caf74d5",
            "7b6037ec47d24ef7b1aa0b1058473993",
            "5b690d7d8a06492998d1bcb0a104985f",
            "c0fe95bdf4df4939a4ab5e117ac2d895",
            "dcdde50a9d3e4102b8b9a3a7858e65a2",
            "9c6a1a23c0c646ad826eaaa611a93987",
            "e4a89313d16f442692b76772d1df8a61",
            "51497259711346e585ede1e510bfe58f",
            "2f7ad17f85c648019c88af564bdff2a1",
            "a3eba3700d9a454da574edfe71f046f9",
            "6cc7c30ee5c24f38a39cc2311c7f2657",
            "7bd87a9f2ba74fa5903c24f4773210d0",
            "8b6079802bac4a9fad1fff3aab77f5ce",
            "7a7a95b99e7c478386f46f96ed9a3307",
            "5cb43e400e494636b6af86fac6c0d4bc",
            "7c81d7500fd94df785f7a3c48c6ce875",
            "2daedbc298ba4f9c94830612bef6f003",
            "7b1fa03edf2b4e1e9c2a41a2ddbfb68e",
            "071a2c80c66847f1b38a3131929bd968",
            "361efe9afd264ef1bfb102e355b447e8",
            "a91b8365d1374f4299d1adcd1a30ae26",
            "21e2183c359444f791f037475072e6a2",
            "2b7812cf356a445393c98e9407d2b2ea",
            "895248d4739b456da0b62f0c855b6878",
            "d5d3aff475cc44ec8baaf20dd1789ad4",
            "91e886cea1a74ae594b39c5ab87ceffc",
            "a40d843169f04a47b9c1420b203d3413",
            "49c93c576cf7480e87f68952671dd33a",
            "20b99e6e53344c56b2e9932481e5e0bd",
            "0f6e563ebf594aecb3416dd2a5588587",
            "399f17ec3569404589a97ce7e556a242",
            "c307bc975fa74ae5b9e6202e02fd9980",
            "8fe7a84f4e2f43249aa1e8b39ec49e8b",
            "ef9b4f85cb8d41f69a575a2c0a62d520",
            "57a8482a13d8401ea18c41fac647f082",
            "d49ca3bfd0ba409890799a3605b8b126",
            "a949d7103f8a4cd983f0898f48f99211",
            "249811e2170c44ddbd114c4271864d91",
            "f627fb2d7a71480db09a95c39c9ab0bb",
            "530c4d1f43c64adab3ecd311ce076603",
            "3eaecf9ef81c430dbd92461260b8e2e0",
            "341b5bc410ff4e42ad2d97a628e5a80f",
            "8b36c5f2f9e1402297d129c1fc71b7c6",
            "4f997f5f39d0467caf0ec71418236b5c",
            "eb68d9257a624d91a710398ce3af663a",
            "56455c66a5c242ec97526ab42dcc665c",
            "71a4210ce01444dc8a96ffe3d490fabd",
            "3a1a30b188a148ddbf3418e61e14ac23",
            "af8b8437d09b43829151b3e6cb9790e1",
            "e7f4b9c12c9e4852a1ff88f344fa17a5",
            "facef579523e439d900a6d4c445a0083",
            "a98352522df54aac9f3a881d6915022f",
            "1bb74c20e9de4a5792813ae46d985e57",
            "c66bd7fd8fe841e9a4bef2ad27bed054",
            "6f673897e6e3487fa94a3fff4bbb41c9",
            "e0155781c2bb4ea8a6892731ebd19394",
            "098898eee10d499db48323d9b7afdcd9",
            "b1b9d8fb9c8c4c80ae19bceca76e16ec",
            "08c4b81c85f044a2be98bcc8ec00ec7c",
            "edda85202e8749bcac6fec0c1cd11670",
            "78ceb42c16894be3b720ed17345003a3",
            "0291e7f7698d43d6aa96345cd79fb023",
            "4e010688c846476eb6d0f3901efa430a",
            "f83db075e2c743faa72c7d3eed317b35",
            "df9e65b9a1614e4a8df759255631b059",
            "806a126d6d664125a7684c44717910b3",
            "10051da490574e98b95510efb54e140a",
            "a57fc8716d004ef8ae7efd45f79e6f8e",
            "0e2fb871ad3e46cca3f0a3799bb2a7b0",
            "b91d05fe10374c5b9ba1664d60b56e91",
            "8dcef1bdbf1c49e6b2b43dea978d451d",
            "b73236d440bc43ca9e04b3cb8ce03fb6",
            "3e3f0c9e9877401dba815f4a5609282b",
            "da77d1e26bfc47f28ebe5d0a28ea89b1"
          ]
        },
        "id": "ITBT2Y-P-0mi",
        "outputId": "28d2ca68-0338-4d46-ea38-7eed62992ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/658 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6590ab3cce064639b2be40305df3bb58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f7ad17f85c648019c88af564bdff2a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "361efe9afd264ef1bfb102e355b447e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "399f17ec3569404589a97ce7e556a242"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "341b5bc410ff4e42ad2d97a628e5a80f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bb74c20e9de4a5792813ae46d985e57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/551M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f83db075e2c743faa72c7d3eed317b35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between \"deep learning\" and \"artificial intelligence\" is: 0.591\n",
            "Cosine similarity between \"deep learning\" and \"deep diving\" is: 0.563\n",
            "Cosine similarity between \"deep learning\" and \"artificial snow\" is: 0.370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_sim_1_0 = 1 - cosine(embeddings[1], embeddings[0])\n",
        "cosine_sim_1_2 = 1 - cosine(embeddings[1], embeddings[2])\n",
        "cosine_sim_1_3 = 1 - cosine(embeddings[1], embeddings[3])\n",
        "\n",
        "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[1], texts[0], cosine_sim_1_0))\n",
        "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[1], texts[2], cosine_sim_1_2))\n",
        "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[1], texts[3], cosine_sim_1_3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjSreVoIGKK-",
        "outputId": "2efb9c7a-bdd0-4e26-a18e-336fe323fe76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between \"artificial intelligence\" and \"deep learning\" is: 0.591\n",
            "Cosine similarity between \"artificial intelligence\" and \"deep diving\" is: 0.365\n",
            "Cosine similarity between \"artificial intelligence\" and \"artificial snow\" is: 0.497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy1sHKvzHSPN",
        "outputId": "579d9bfa-5511-4afd-f069-3dc18d3c3e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[22089,  4673, 50256],\n",
              "        [  433,  9542,  4430],\n",
              "        [22089, 23186, 50256],\n",
              "        [  433,  9542,  6729]]), 'attention_mask': tensor([[1, 1, 0],\n",
              "        [1, 1, 1],\n",
              "        [1, 1, 0],\n",
              "        [1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Symmetric Semantic Search Binary Encoder Sentence Transformer"
      ],
      "metadata": {
        "id": "Oi72QKU5N9qN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install git+https://github.com/UKPLab/sentence-transformers.git"
      ],
      "metadata": {
        "id": "QVYG2s_UMLpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "texts = [\n",
        "    \"deep learning\",\n",
        "    \"artificial intelligence\",\n",
        "    \"deep diving\",\n",
        "    \"artificial snow\",\n",
        "]\n",
        "\n",
        "model = SentenceTransformer(\"Muennighoff/SGPT-125M-weightedmean-nli-bitfit\")\n",
        "embeddings = model.encode(texts)\n",
        "\n",
        "cosine_sim_0_1 = 1 - cosine(embeddings[0], embeddings[1])\n",
        "cosine_sim_0_2 = 1 - cosine(embeddings[0], embeddings[2])\n",
        "cosine_sim_0_3 = 1 - cosine(embeddings[0], embeddings[3])\n",
        "\n",
        "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[1], cosine_sim_0_1))\n",
        "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[2], cosine_sim_0_2))\n",
        "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[3], cosine_sim_0_3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229,
          "referenced_widgets": [
            "8a9c42f7e9034fffbec1ffd2ce11f011",
            "7c547fa412ee48219b77588323d9c3fc",
            "2f2da1c965a6494e9dad6186f029f31f",
            "04f5d7e9fa544f6dbfc4523171db7b20",
            "e15ecad1f0ee46a6a39afa21dab2f45c",
            "511a4564651042ad8ad74cc16d73d769",
            "ac6e1f815a774f9fb775cccc08dfcbc4",
            "b76f1d6e8fd049bbbd4b7c04c98f1c17",
            "d1f227da4d86449b96c927132753011e",
            "d98396b02b734ad0b51c8136db5fa3ea",
            "4b06bfd51e5a4590b0de242c63ac31dd",
            "0f8b0ff023aa4ea09c5949fe4bb53d6c",
            "c4f5b7e5ac82485787d587875ad1614e",
            "7ef20747354940c3a552a2a3bbbf85b3",
            "895917cd5a2348e78373c2b061fef919",
            "5df57f57a28c4a2aa3f110c2ddbfd001",
            "7d2cb20f3a414d1a92def544ef8d6ad9",
            "5b41eb3628da4807955875c9f122ce67",
            "9ed017090e0a42b5886b8c95bb38efd3",
            "0f88161474b84e458bf6af6b48e647f4",
            "7d9d2086b0884f71bec197de6807f760",
            "a3fef6afbbfa4899892c3b4a57253f25",
            "940320c3dea74570aab1e55b01906ede",
            "7dec4304d3394db8be08a131023abae7",
            "99f00d392e1a4c8e8c4b51b494523e3a",
            "e0f09ad1860d4930b44024f974a728fe",
            "c7568f992cd14967ab550244b4a42d42",
            "df1ad86e64b84764b3e258cea0939ea4",
            "d6ba7c345400451a92389dc29bc20091",
            "adf9890b57ce448a9245a671d232cba0",
            "9d3db54737494e00a8f184e8c11be06b",
            "3c41d820ea994d2bbc9d3139d13b6efa",
            "54c5c5f3cb1e4623bc234ae38d2e84d0",
            "76f700535c4248b6af56734a3440625f",
            "b2c0bc699d2b49dbbc926d465d89a8bc",
            "9d0835c24b904f7292bebe7d1186e813",
            "c7c34f209368453486f3b79674a20ee1",
            "bada788efc61487da48e34c6828a70a6",
            "6716abccd73f44acb7e521e0f1b53fef",
            "d00ba6f431504915b07ff9b9bc61d053",
            "ca0fb050b1374ca0bd44af6ba36cce51",
            "ffc2e09b8f2744059b678782f4a982ad",
            "0808363e11734b2daa489db8ebbbe4f1",
            "d59c030b5b434d548dc2d5f5d6454f1c",
            "75c742f6a5674d50a59f36f3573f3f93",
            "777ca9cedf5d4ccb99bcd49bb50ff745",
            "8098c10c373e4e329a4fae88d4b14c15",
            "d08c43557e4e41e09265a09ebf4aa1cb",
            "ebb311653b324d458f108fcb541c6e98",
            "ce9104d95024441bae99192b2efa32cd",
            "6e99a8e0092a4d1aa9d2bad5c9096166",
            "ca1832a8e5e6401b993519a05f65ef0e",
            "794999a0667e4785af13647176207574",
            "952a62b3f45c43d78858cd7a3e46f616",
            "230ca505569549f4a413f7ef9424fb4c"
          ]
        },
        "id": "vkrG_6BgMDZ9",
        "outputId": "fa4e943f-2a26-4aed-8b4f-2ccecac056c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a9c42f7e9034fffbec1ffd2ce11f011"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f8b0ff023aa4ea09c5949fe4bb53d6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/116k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "940320c3dea74570aab1e55b01906ede"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76f700535c4248b6af56734a3440625f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/270 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75c742f6a5674d50a59f36f3573f3f93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between \"deep learning\" and \"artificial intelligence\" is: 0.591\n",
            "Cosine similarity between \"deep learning\" and \"deep diving\" is: 0.563\n",
            "Cosine similarity between \"deep learning\" and \"artificial snow\" is: 0.370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Referenced From: **<br>\n",
        "[**SGPT Symmetric Bi-Encoder Sentence Transformer**](https://huggingface.co/bigscience-data/sgpt-bloom-1b7-nli)"
      ],
      "metadata": {
        "id": "9BdoJnepPGOv"
      }
    }
  ]
}