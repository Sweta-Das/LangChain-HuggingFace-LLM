{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPhzhAR3uOpzWrvIFp+fNT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sweta-Das/LangChain-HuggingFace-LLM/blob/main/2_model_prompts_parsing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "VlPoJNoWeARt"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install langchain\n",
        "%pip install huggingface_hub\n",
        "%pip install transformers\n",
        "%pip install accelerate\n",
        "%pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain import HuggingFaceHub\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "HadKHTUnc6Tw"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PromptTemplate Class**: Creates reusable string templates for constructing prompts for LLM (similar to f-string in Python).<br>\n",
        "**LLMChain Class**: Most basic building block for interacting with LLMs. It utilizes Prompt Template class to define prompt structure sent to the LLM. It takes the formatted prompt and interacts with the underlying LLM connected to Langchain."
      ],
      "metadata": {
        "id": "Ka0hOoE6dayD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using HuggingFace API Key"
      ],
      "metadata": {
        "id": "MU3ksm97fpMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'HUGGINGFACEHUB_API_TOKEN'"
      ],
      "metadata": {
        "id": "QaoZ4o4fgTZu"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Question: {question}\n",
        "Answer: Let's think step by step.\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
      ],
      "metadata": {
        "id": "9HYa320NkjQI"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using **Chain**: contains 2 components;<br>\n",
        "  - prompt : uses prompt template <br>\n",
        "  - llm : model to perform LLM function => [google/flan-t5.xl](https://huggingface.co/google/flan-t5-base)<br>"
      ],
      "metadata": {
        "id": "DqIJ5_ekf0Xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(\n",
        "    prompt = prompt,\n",
        "    llm = HuggingFaceHub(\n",
        "        repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "        model_kwargs={\n",
        "            \"temperature\": 0.1,\n",
        "            \"max_length\": 100\n",
        "        },\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "IKGEXiLJfw-3"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the capital of France?\"\n",
        "print(llm_chain.run(question))"
      ],
      "metadata": {
        "id": "yJGuAlwzjna5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97f59fc7-462d-4067-d64b-48ed1b15f2a7"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the capital of France?\n",
            "Answer: Let's think step by step.\n",
            "\n",
            "The capital of a country is the city where the government resides.\n",
            "\n",
            "In France, the government resides in Paris.\n",
            "\n",
            "Therefore, Paris is the capital of France.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who is Abraham Lincoln? What is he famous for?\"\n",
        "print(llm_chain.run(question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olxxPSiGh5VW",
        "outputId": "9aaf9b82-b078-4cd5-fc35-4305f3ffcca6"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Who is Abraham Lincoln? What is he famous for?\n",
            "Answer: Let's think step by step.\n",
            "\n",
            "Abraham Lincoln was the 16th President of the United States, serving from March 1861 until his assassination in April 1865. He is famous for leading the nation through its greatest internal crisis, the American Civil War, and abolishing slavery.\n",
            "\n",
            "He was born on February 12, 1809, in a log cabin in Hardin County, Kentucky. He grew up in a poor family and had little formal education.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using HuggingFace Model Locally"
      ],
      "metadata": {
        "id": "yIUFFbQMkmGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install accelerate\n",
        "%pip install -i https://pypi.org/simple/ bitsandbytes"
      ],
      "metadata": {
        "id": "6wMUIiDwmILJ"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import accelerate\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "gsu4RvTNiB2P"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'google/flan-t5-small'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name,\n",
        "                                              device_map='auto')"
      ],
      "metadata": {
        "id": "mdSfcOxllJue"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 'google/flan-t5-small' LLM model uses T5TokenizerFast as tokenizer."
      ],
      "metadata": {
        "id": "0BGzV7U_lsr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=128\n",
        ")\n",
        "local_llm = HuggingFacePipeline(pipeline=pipeline)"
      ],
      "metadata": {
        "id": "OSvioVJ2llEn"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sending prompt directly\n",
        "local_llm.invoke('What is the capital of China?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IVCIjgUXotQ-",
        "outputId": "dd9a6e51-153c-4081-d80c-eae9007f7353"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'shanghai'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sending prompt through LLMChain\n",
        "llm_chain = LLMChain(\n",
        "    prompt = prompt,\n",
        "    llm = local_llm\n",
        ")\n",
        "question = \"What is the capital of England?\"\n",
        "print(llm_chain.run(question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSbKkOQipPGS",
        "outputId": "54a30e67-047a-400c-e9fc-8702d0c1d7a0"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "England is the capital of England. So, the answer is England.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat Prompt Template"
      ],
      "metadata": {
        "id": "j-7pq28taCng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "Interprete the text and evaluate the text.\n",
        "sentiment: is the text in a positive, neutral or negative sentiment?\n",
        "subject: What subject is the text about? Use exactly one word.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "sentiment\n",
        "subject\n",
        "\n",
        "text: {question}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "XA4W9J2qaCN9"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template=template)\n",
        "chain = LLMChain(\n",
        "    prompt=prompt_template,\n",
        "    llm=local_llm)\n",
        "\n",
        "chain.predict(question=\"I ordered Pizza Salami and it was awesome!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6mZawDnQaJ1F",
        "outputId": "2516c700-8274-47a1-99b1-c57e3f1477f8"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Real World Example with ResponseSchema, Templates, Chains, OutputParsers"
      ],
      "metadata": {
        "id": "tT8OqJDtbhwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "Interprete the text and evaluate the text.\n",
        "sentiment: is the text in a positive, neutral or negative sentiment?\n",
        "subject: What subject is the text about? Use exactly one word.\n",
        "\n",
        "Just return the JSON, do not add ANYTHING, NO INTERPRETATION!\n",
        "\n",
        "text: {input}\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_GGLpw8WitBz"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = LLMChain(\n",
        "    prompt = ChatPromptTemplate.from_template(template=template),\n",
        "    llm = HuggingFaceHub(\n",
        "        repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "        model_kwargs={\n",
        "            \"temperature\": 0.1,\n",
        "            \"max_length\": 100\n",
        "        },\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "rRamh1j7dn3x"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser\n",
        "\n",
        "sentiment_schema = ResponseSchema(\n",
        "    name=\"sentiment\",\n",
        "    description=\"Is the text positive, neutral or negative? Only provide these words\",\n",
        ")\n",
        "subject_schema = ResponseSchema(\n",
        "    name=\"subject\", description=\"What subject is the text about? Use exactly one word.\"\n",
        ")\n",
        "price_schema = ResponseSchema(\n",
        "    name=\"price\",\n",
        "    description=\"How expensive was the product? Use None if no price was provided in the text\",\n",
        ")\n",
        "\n",
        "response_schemas = [sentiment_schema, subject_schema, price_schema]"
      ],
      "metadata": {
        "id": "WoYyz-CNahxR"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "format_instructions = parser.get_format_instructions()\n",
        "format_instructions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "kr4cEDmBbukK",
        "outputId": "3b6bc2a2-0c89-407b-b959-62bf8d427303"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"sentiment\": string  // Is the text positive, neutral or negative? Only provide these words\\n\\t\"subject\": string  // What subject is the text about? Use exactly one word.\\n\\t\"price\": string  // How expensive was the product? Use None if no price was provided in the text\\n}\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "format_instructions = parser.get_format_instructions()\n",
        "\n",
        "messages = {\n",
        "    \"input\": \"I ordered Pizza Salami for 9.99$ and it was awesome!\",\n",
        "    \"format_instructions\": format_instructions,\n",
        "}\n",
        "\n",
        "response = chat.invoke(messages)\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDxA6QD1b2LB",
        "outputId": "c12de960-21bf-457d-d058-b17bc74827a0"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'I ordered Pizza Salami for 9.99$ and it was awesome!',\n",
              " 'format_instructions': 'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"sentiment\": string  // Is the text positive, neutral or negative? Only provide these words\\n\\t\"subject\": string  // What subject is the text about? Use exactly one word.\\n\\t\"price\": string  // How expensive was the product? Use None if no price was provided in the text\\n}\\n```',\n",
              " 'text': 'Human: \\nInterprete the text and evaluate the text.\\nsentiment: is the text in a positive, neutral or negative sentiment?\\nsubject: What subject is the text about? Use exactly one word.\\n\\nJust return the JSON, do not add ANYTHING, NO INTERPRETATION!\\n\\ntext: I ordered Pizza Salami for 9.99$ and it was awesome!\\n\\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"sentiment\": string  // Is the text positive, neutral or negative? Only provide these words\\n\\t\"subject\": string  // What subject is the text about? Use exactly one word.\\n\\t\"price\": string  // How expensive was the product? Use None if no price was provided in the text\\n}\\n```\\n\\n```json\\n{\\n\\t\"sentiment\": \"positive\",\\n\\t\"subject\": \"pizza\",\\n\\t\"price\": \"9.99$\"\\n}\\n```'}"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "response = json.dumps(response)\n",
        "output_dict = parser.parse(response[2])\n",
        "output_dict"
      ],
      "metadata": {
        "id": "sFT3VZ50lCMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{\"sentiment\": \"positive\", \"subject\": \"pizza\", \"price\": \"9.99$\"}"
      ],
      "metadata": {
        "id": "1ei78ReAqF2w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qQIgYJq3qHFe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}